{
 "metadata": {
  "name": "",
  "signature": "sha256:0437655e17f37e706aec6c280ac762ff3596e13edfdc9faca9f11ad10def9309"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "from pymongo import MongoClient\n",
      "from requests.auth import HTTPBasicAuth\n",
      "from collections import Counter\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.cluster import KMeans\n",
      "from nltk.corpus import stopwords\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from gensim.models import Word2Vec\n",
      "from gensim.models import Doc2Vec\n",
      "from nltk.stem import SnowballStemmer\n",
      "import re\n",
      "import gensim\n",
      "from gensim.models.doc2vec import LabeledSentence\n",
      "from gensim.models.ldamodel import LdaModel\n",
      "from gensim.models.ldamulticore import LdaMulticore\n",
      "from gensim.corpora.textcorpus import TextCorpus\n",
      "from sklearn.svm import SVC\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn.cluster import _k_means\n",
      "#a = requests.get('https://issues.apache.org/jira/browse/HIVE-8710')\n",
      "#client = MongoClient('localhost', 27017)\n",
      "#db = client['helpdesk']\n",
      "#coll = db['tickets']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "sklearn.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'0.15.2'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#baseurl = 'https://issues.apache.org/jira/browse/'\n",
      "#project = 'HIVE'\n",
      "#for x in range(6418,8711):\n",
      "#    ticket = make_db_entry(baseurl, project, x)\n",
      "#    if x % 100 == 0:\n",
      "#        print 'x:', x, ' status: ', ticket['http status']\n",
      "#    insert_db_entry(ticket,coll)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#def make_db_entry(baseurl, project, num):\n",
      "#    url = baseurl + project + '-' + str(num)\n",
      "#    a = requests.get(url)\n",
      "#    ticket = {'url': url,\n",
      "#              'ticketnum': num,\n",
      "#              'project': project,\n",
      "#              'http status': a.status_code,\n",
      "#              'text': a.text}\n",
      "#    return ticket\n",
      "#\n",
      "#def insert_db_entry(ticket, coll):\n",
      "#    coll.insert(ticket)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#coll.find({'http status': 200}).count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#coll.find({},{\"$max\": {\"ticketnum\": 1}}).count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 235
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for x in a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baseurl = 'https://api.github.com/repos/saltstack/salt/issues?sort=updated&direction=asc&state=all'\n",
      "#a = requests.get('https://api.github.com/repos/saltstack/salt/issues?sort=updated&direction=asc&state=all')\n",
      "client = MongoClient('localhost', 27017)\n",
      "db = client['helpdesk']\n",
      "coll = db['github_saltstack']\n",
      "project = 'saltstack'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def db_loop_entry(baseurl, project, coll, page):\n",
      "    url = baseurl + '&page=' + str(page)\n",
      "    a = requests.get(url, auth=HTTPBasicAuth(uid,secret_pass))\n",
      "    json_list = a.json()\n",
      "    if len(json_list) > 0:\n",
      "      for j_obj in json_list:\n",
      "         ticket = {'url': url,\n",
      "                   'project': project,\n",
      "                   'json': j_obj}\n",
      "         coll.insert(ticket)\n",
      "      return True\n",
      "    return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#latest = db_loop_entry(baseurl, project, coll)\n",
      "page = 1\n",
      "more = True\n",
      "while more:\n",
      "    more = db_loop_entry(baseurl, project, coll, page)\n",
      "    if page % 20 == 0:\n",
      "        print page\n",
      "    page += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20\n",
        "40"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "80"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "120"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "140"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "160"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "180"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "220"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "240"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "260"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "280"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "320"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "340"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "360"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "380"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "420"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "440"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "460"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "480"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "520"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "540"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "560"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_with_labels = 0\n",
      "count = 0\n",
      "count_of_labels = 0\n",
      "all_labels = Counter()\n",
      "for x in coll.find():\n",
      "    num_labels = len(x['json']['labels'])\n",
      "    if num_labels > 0:\n",
      "        count_with_labels += 1\n",
      "        count_of_labels += num_labels\n",
      "    for label in x['json']['labels']:\n",
      "        all_labels[label['name']] += 1\n",
      "    count += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print count_with_labels\n",
      "print count\n",
      "print count_of_labels\n",
      "print all_labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5146\n",
        "17129\n",
        "9657\n",
        "Counter({u'Bug': 2430, u'Medium Severity': 1301, u'Feature': 1141, u'Low Severity': 604, u'Documentation': 475, u'Fixed Pending Verification': 473, u'in progress': 460, u'Bugfix - [Done] back-ported': 371, u'High Severity': 347, u'Low-Hanging Fruit': 340, u'Windows': 221, u'Salt-Cloud': 216, u'Regression': 158, u'Pending Discussion': 135, u'Duplicate': 128, u'Expected Behavior': 127, u'Cannot Reproduce': 106, u'Info Needed': 99, u'Question': 92, u'Salt-SSH': 92, u'Packaging': 70, u\"Won't Fix For Now\": 40, u'Execution Module': 38, u'State Module': 37, u'Upstream Bug': 36, u'Needs Testcase': 30, u'Multi-Master': 16, u'Critical': 15, u'RAET': 14, u'Confirmed': 14, u'Core': 14, u'Salt-API': 13, u'tt:not_started': 1, u'Bugfix - back-port': 1, u'Other Module': 1, u'Blocker': 1})\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x in coll.find():\n",
      "  if 'body' not in x['json'] or x['json']['body'] is None:\n",
      "    x['json']['body'] = ''\n",
      "  if 'text' not in x['json'] or x['json']['text'] is None:\n",
      "    x['json']['text'] = ''\n",
      "  x['json']['text'] = x['json']['body'] + x['json']['title']\n",
      "  for label in x['json']['labels']:\n",
      "        x['json']['label' + label['name']] = 1\n",
      "  coll.update({\"_id\": x['_id']},x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def token_stem(sentence,stemmer):\n",
      "    date = re.compile(u'(201[0-9]+)')\n",
      "    sentence = date.sub('regex_date',sentence)\n",
      "    num = re.compile(u'([0-9]+)')\n",
      "    sentence = num.sub('regex_num',sentence) # replace with # of digits\n",
      "    pyfile = re.compile(u'(\\/[\\w\\/]+.py)')\n",
      "    sentence = pyfile.sub('regex_pyfile',sentence)\n",
      "    dunders = re.compile(u'(__\\w+|\\w+__)')\n",
      "    sentence = dunders.sub('regex_dunders',sentence)\n",
      "    return [stemmer.stem(x) for x in re.findall(u'(?u)\\\\b\\\\w\\\\w+\\\\b',sentence.lower())]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = []\n",
      "y_bug = []\n",
      "y_feature = []\n",
      "#y_documentation = []\n",
      "all_sentences = []\n",
      "all_labels = []\n",
      "sentences_for_word2vec = []\n",
      "stemmer = SnowballStemmer('english')\n",
      "for i, x in enumerate(coll.find()):\n",
      "    all_sentences.append(token_stem(x['json']['text'],stemmer))\n",
      "    sentences_for_word2vec.append(token_stem(x['json']['text'],stemmer))\n",
      "    all_labels.append([y['name'] for y in x['json']['labels']])\n",
      "    if len(x['json']['labels']) > 0:\n",
      "      if 'labelBug' in x['json'] or 'labelFeature' in x['json']:\n",
      "          X.append(token_stem(x['json']['text'],stemmer))\n",
      "      #X.append(x['json']['title'])\n",
      "          if 'labelBug' in x['json']:\n",
      "              y_bug.append(1)\n",
      "          else:\n",
      "              y_bug.append(0)\n",
      "          if 'labelFeature' in x['json']:\n",
      "              y_feature.append(1)\n",
      "          else:\n",
      "              y_feature.append(0)\n",
      "      #if 'labelDocumentation' in x['json']:\n",
      "      #    y_documentation.append(1)\n",
      "      #else:\n",
      "      #    y_documentation.append(0)\n",
      "y_bug = np.array(y_bug)\n",
      "y_feature = np.array(y_feature)\n",
      "y_comb = np.argmax(np.hstack((y_feature.reshape(-1,1), y_bug.reshape(-1,1))),axis=1)\n",
      "#y_documentation = np.array(y_documentation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = [' '.join(x) for x in X]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec = CountVectorizer(stop_words='english',max_features=10000)\n",
      "vec_t = vec.fit_transform(' '.join(x) for x in all_sentences)\n",
      "id2word = {v: k for k, v in vec.vocabulary_.iteritems()}\n",
      "vec_corpus = gensim.matutils.Sparse2Corpus(vec_t.T)\n",
      "lda = LdaMulticore(corpus=vec_corpus,id2word=id2word,iterations=200,num_topics=20,passes=20,workers=4)\n",
      "lda.save('ldalippi.lda')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labeled_counts = vec.transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx = np.random.rand(labeled_counts.shape[0]) < .8\n",
      "labeled_counts_train = labeled_counts[idx]\n",
      "labeled_counts_test = labeled_counts[~idx]\n",
      "y_comb_train = y_comb[idx]\n",
      "y_comb_test = y_comb[~idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labeled_probas = lda.inference(gensim.matutils.Sparse2Corpus(labeled_counts.T))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labeled_probas_train = labeled_probas[0][idx]\n",
      "labeled_probas_test = labeled_probas[0][~idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_lda = LogisticRegression()\n",
      "lr_lda.fit(labeled_probas_train,y_comb_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 205,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_lda.score(labeled_probas_test,y_comb_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 264,
       "text": [
        "0.69390581717451527"
       ]
      }
     ],
     "prompt_number": 264
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = TfidfVectorizer(max_features=10000,stop_words=set(stopwords.words()))\n",
      "tfidf_t = tfidf.fit_transform(' '.join(x) for x in X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf_t_train = tfidf_t[idx]\n",
      "tfidf_t_test = tfidf_t[~idx]\n",
      "y_bug_train = y_bug[idx]\n",
      "y_bug_test = y_bug[~idx]\n",
      "y_feature_train = y_feature[idx]\n",
      "y_feature_test = y_feature[~idx]\n",
      "#y_documentation_train = y_documentation[idx]\n",
      "#y_documentation_test = y_documentation[~idx]\n",
      "\n",
      "#y_comb = np.argmax(np.hstack((np.zeros((len(y_feature),1)),y_feature.reshape(-1,1), y_bug.reshape(-1,1))),axis=1)\n",
      "y_comb = np.argmax(np.hstack((y_feature.reshape(-1,1), y_bug.reshape(-1,1))),axis=1)\n",
      "y_comb_train = y_comb[idx]\n",
      "y_comb_test = y_comb[~idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_bug = LogisticRegression()\n",
      "lr_bug.fit(tfidf_t_train, y_bug_train)\n",
      "confusion_matrix(lr_bug.predict(tfidf_t_test),y_bug_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 267,
       "text": [
        "array([[138,  24],\n",
        "       [ 87, 473]])"
       ]
      }
     ],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_feature = LogisticRegression()\n",
      "lr_feature.fit(tfidf_t_train, y_feature_train)\n",
      "confusion_matrix(lr_feature.predict(tfidf_t_test),y_feature_test)\n",
      "# high FPR, low FNR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 268,
       "text": [
        "array([[473,  85],\n",
        "       [ 24, 140]])"
       ]
      }
     ],
     "prompt_number": 268
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lr_documentation = LogisticRegression()\n",
      "#lr_documentation.fit(tfidf_t_train, y_documentation_train)\n",
      "#confusion_matrix(lr_documentation.predict(tfidf_t_test), y_documentation_test)\n",
      "# high FPR, low FNR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 269
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_in_bug_feature_test = np.hstack((\n",
      "                           lr_bug.predict_proba(tfidf_t_test)[:,0].reshape(-1,1),\n",
      "                           lr_feature.predict_proba(tfidf_t_test)[:,0].reshape(-1,1),\n",
      "                           lr_lda.predict_proba(labeled_probas_test)[:,0].reshape(-1,1),\n",
      "                           X_kmeans_test))\n",
      "lr_in_bug_feature_train = np.hstack((\n",
      "                              lr_bug.predict_proba(tfidf_t_train)[:,0].reshape(-1,1),\n",
      "                              lr_feature.predict_proba(tfidf_t_train)[:,0].reshape(-1,1),\n",
      "                              lr_lda.predict_proba(labeled_probas_train)[:,0].reshape(-1,1),\n",
      "                              X_kmeans_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 270
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lr = LogisticRegression()\n",
      "#lr = RandomForestClassifier(n_estimators=5000,n_jobs=-1)\n",
      "#lr.fit(lr_in_bug_feature_train,y_comb_train)\n",
      "print confusion_matrix(lr.predict(lr_in_bug_feature_test),y_comb_test)\n",
      "print f1_score(lr.predict(lr_in_bug_feature_test),y_comb_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[171  47]\n",
        " [ 54 450]]\n",
        "0.899100899101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 272
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = Word2Vec(sentences_for_word2vec, size=100, window=5, min_count=5, workers=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 273
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model.most_similar(['featur'])\n",
      "print model.most_similar(['bug'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'consider', 0.7025125026702881), (u'implement', 0.669681191444397), (u'submit', 0.6637053489685059), (u'conveni', 0.6313135623931885), (u'love', 0.6143792271614075), (u'whiteing', 0.6130695343017578), (u'abstract', 0.611484706401825), (u'thank', 0.6086292266845703), (u'effici', 0.6042249202728271), (u'perhap', 0.602887749671936)]\n",
        "[(u'weird', 0.6439695358276367), (u'believ', 0.6423788070678711), (u'obvious', 0.6232681274414062), (u'issu', 0.6228752732276917), (u'massiv', 0.6099817156791687), (u'annoy', 0.6000193357467651), (u'somewhat', 0.5926418900489807), (u'hope', 0.5915759205818176), (u'behaviour', 0.5898837447166443), (u'regress', 0.5898414254188538)]\n"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from j_kmeans import Kmeans\n",
      "from copy import deepcopy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from j_kmeans import Kmeans\n",
      "scores = []\n",
      "for i in xrange(1,20,1):\n",
      "  print i\n",
      "  km = Kmeans(i)\n",
      "  km.fit(model.syn0)\n",
      "  scores.append(km.compute_sse(model.syn0))\n",
      "plt.plot(range(1,20,1),scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "2\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 213,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fbd619bb090>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZIkSZIkSZIkSZIkSSoW/x/d+GCi7itl0AAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fbd61381f50>"
       ]
      }
     ],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = Word2Vec(sentences_for_word2vec, size=100, window=5, min_count=5, workers=4)\n",
      "km = Kmeans(5)\n",
      "km.fit(model.syn0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distances = np.array(km.calc_distances(model.syn0))\n",
      "b = distances == np.min(distances,axis=0)\n",
      "#distances_normed = distances/distances.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#word_features = np.hstack((np.array(distances).T,b.T * 1))\n",
      "cluster_distances = np.array(distances).T\n",
      "closest_clusters = b.T * 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_kmeans = []\n",
      "revdict = {w: i for i,w in enumerate(model.index2word)}\n",
      "for doc in X:\n",
      "    x_dists = np.zeros(len(cluster_distances[0]))\n",
      "    x_closest = np.zeros(len(closest_clusters[0]))\n",
      "    count = 0\n",
      "    for word in doc.split():\n",
      "      if word in revdict:\n",
      "        count += 1\n",
      "        x_dists = x_dists + cluster_distances[revdict[word]]\n",
      "        x_closest = x_closest + closest_clusters[revdict[word]]\n",
      "    if count > 0:\n",
      "      x_dists = x_dists / count\n",
      "      x_closest = x_closest / count\n",
      "    X_kmeans.append(np.hstack((x_dists,x_closest)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_kmeans = np.array(X_kmeans)\n",
      "#idx = np.random.rand(X_kmeans.shape[0]) < .8\n",
      "X_kmeans_train = X_kmeans[idx]\n",
      "X_kmeans_test = X_kmeans[~idx]\n",
      "#y_comb_train = y_comb[idx]\n",
      "#y_comb_test = y_comb[~idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_kmeans = LogisticRegression()\n",
      "lr_kmeans.fit(X_kmeans_train,y_comb_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 225,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_kmeans.score(X_kmeans_test,y_comb_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 228,
       "text": [
        "0.77146814404432129"
       ]
      }
     ],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'confusion mat', confusion_matrix(lr_kmeans.predict(X_kmeans_test),y_comb_test)\n",
      "print 'f1 score', f1_score(lr_kmeans.predict(X_kmeans_test),y_comb_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "confusion mat [[121  61]\n",
        " [104 436]]\n",
        "f1 score 0.840887174542\n"
       ]
      }
     ],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 222,
       "text": [
        "u'can we have share group ownership of thing like etc salt pki master and etc salt pki minion instead of just root like salt group that user can belong to most so that command complet can work share group ownership of runtim file'"
       ]
      }
     ],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d2vmodel = Doc2Vec(workers=4,dm=1,window=5,size=100)\n",
      "d2vmodel.build_vocab(doc2vec_inputs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx = np.random.rand(len(doc2vec_inputs),1)[:,0] < .8\n",
      "doc2vec_inputs = np.array(doc2vec_inputs)\n",
      "doc2vec_inputs_train = doc2vec_inputs[idx]\n",
      "doc2vec_inputs_test = doc2vec_inputs[~idx]\n",
      "d2vmodel.train(doc2vec_inputs_train)\n",
      "#d2vmodel.train_words = False\n",
      "#d2vmodel.train_lbls = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "1084896"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for _ in xrange(10):\n",
      "    d2vmodel.train(doc2vec_inputs_train)\n",
      "d2vmodel.train_words = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for _ in xrange(10):\n",
      "    d2vmodel.train(doc2vec_inputs_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc_X_train = []\n",
      "svc_labels_train = []\n",
      "for i in np.where(idx)[0]:\n",
      "    if 'Feature' in labels_for_doc2vec[i] or 'Bug' in labels_for_doc2vec[i]:\n",
      "      try:\n",
      "          svc_X_train.append(d2vmodel['document_' + str(i)])\n",
      "          if 'Feature' in labels_for_doc2vec[i]:\n",
      "            svc_labels_train.append('Feature')\n",
      "          else:\n",
      "            svc_labels_train.append('Bug')\n",
      "      except:\n",
      "          pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d2v_pred_test = []\n",
      "for i in np.where(~idx)[0]:\n",
      "  if 'Feature' in labels_for_doc2vec[i] or 'Bug' in labels_for_doc2vec[i]:\n",
      "    try:\n",
      "      d2v_pred_test.append('Bug' if d2vmodel.similarity('document_' + str(i),'Bug') > d2vmodel.similarity('document_' + str(i),'Feature') else 'Feature')\n",
      "    except:\n",
      "      pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confusion_matrix(d2v_pred_test,svc_labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 271,
       "text": [
        "array([[247, 107],\n",
        "       [261, 107]])"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc_X_test = []\n",
      "svc_labels_test = []\n",
      "for i in np.where(~idx)[0]:\n",
      "    if 'Feature' in labels_for_doc2vec[i] or 'Bug' in labels_for_doc2vec[i]:\n",
      "      try:\n",
      "          svc_X_test.append(d2vmodel['document_' + str(i)])\n",
      "          if 'Feature' in labels_for_doc2vec[i]:\n",
      "            svc_labels_test.append('Feature')\n",
      "          else:\n",
      "            svc_labels_test.append('Bug')\n",
      "      except:\n",
      "          pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.where(~idx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 262,
       "text": [
        "(array([    7,    12,    13, ..., 17108, 17111, 17121]),)"
       ]
      }
     ],
     "prompt_number": 262
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d2vmodel['document_7']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 275,
       "text": [
        "array([-1.06301141,  0.72160089,  0.21649843, -1.22810459, -0.95707494,\n",
        "        0.86748409,  0.34218389,  0.80650574,  1.18310738, -1.1600306 ,\n",
        "        0.95348263,  0.07392813, -0.16517538, -1.02692735, -0.82578593,\n",
        "        0.35484222,  0.20599243,  0.16256531,  0.09396617,  0.1254492 ,\n",
        "       -1.33731127, -1.23829722, -0.14997207, -0.63651669, -0.03734815,\n",
        "        1.26624584,  0.53144407, -0.24750152, -0.29071596, -0.44810644,\n",
        "       -0.33051011,  0.05997924,  0.29622394, -0.23903018,  0.3518917 ,\n",
        "       -0.53524685,  0.17991392,  0.33043408, -0.58286381, -0.1280704 ,\n",
        "       -0.34563866, -0.04717661, -1.0360831 ,  0.22609371, -0.00971113,\n",
        "        0.67466122,  0.80132896, -0.06055323, -1.14883626, -0.45667213,\n",
        "        0.02506318, -0.32766107, -0.45768034,  0.1141206 , -0.14892076,\n",
        "        0.85302365, -0.69850487,  1.08643568, -0.15262324,  0.61211836,\n",
        "        0.78450215,  0.52242422,  0.58334106, -1.42233956, -0.85144264,\n",
        "       -0.62772322,  0.11401065, -0.27002525,  1.52412629, -0.3186709 ,\n",
        "        1.25596535, -0.46686625, -0.00399316,  0.37213916,  0.3275401 ,\n",
        "        0.52132291, -0.81789166,  0.27609602,  0.50951719,  0.22408684,\n",
        "       -0.01033454, -0.26223892, -0.32773718, -0.0155287 ,  0.7312724 ,\n",
        "       -0.03498303,  0.49564126, -0.56272882,  0.13390523, -1.20206177,\n",
        "        0.13672338, -0.30903989, -0.3869426 , -0.46332493,  0.74062783,\n",
        "        1.78022027,  0.3257516 ,  1.19410181,  0.71217412,  0.14102724], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.array([[1,1],[-1,1],[1,1]])\n",
      "y = np.array([1,1]).reshape(-1,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([[ 1,  1],\n",
        "       [-1,  1],\n",
        "       [ 1,  1]])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "array([[1],\n",
        "       [1]])"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1 - np.array(np.dot(x,y.T).T/np.linalg.norm(x,axis=1)/np.linalg.norm(y.T))[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "array([  1.11022302e-16,   1.00000000e+00,   1.11022302e-16])"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.linalg.norm(x,axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "array([ 1.41421356,  1.41421356,  1.41421356])"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.linalg.norm((x - y.T),axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "array([ 0.,  2.,  0.])"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "array([[1, 1]])"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "array([[ 1,  1],\n",
        "       [-1,  1],\n",
        "       [ 1,  1]])"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "array([[1],\n",
        "       [1]])"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}